Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Is Training
10000,1.4133807,14.719874804381847,0.5224855,0.569620253164557,0.569620253164557,0.06976833,0.24903591,0.0002969954,1.0
20000,1.3873019,9.846572361262242,0.93918425,0.9783783783783784,0.9783783783783784,0.011036051,0.24324378,0.00029092762,1.0
30000,1.3736618,6.70945426594927,0.95639706,0.9945904173106646,0.9945904173106646,0.0039439574,0.2393185,0.00028496055,1.0
40000,1.344357,6.403860430586488,0.9567808,0.9903846153846154,0.9903846153846154,0.0066352906,0.2473305,0.00027899715,1.0
50000,1.3169585,6.0238931834153195,0.9661367,0.9950738916256158,0.9950738916256158,0.0023256687,0.23806438,0.0002729972,1.0
